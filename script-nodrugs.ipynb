{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# O mesmo que o script2, mas com a opção de adicionar uma blacklist de codigos brite (kegg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A abrir ficheiro...\n"
     ]
    }
   ],
   "source": [
    "# Abre o ficheiro .tsv\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "print ('A abrir ficheiro...')\n",
    "file = filedialog.askopenfilename(filetypes = [(\"TSV\",\"*.tsv\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A iniciar...\n"
     ]
    }
   ],
   "source": [
    "print ('A iniciar...')\n",
    "start_time = time.time()\n",
    "h = []\n",
    "with open(file, 'r') as f:\n",
    "    x = f.read()\n",
    "    x = x.split('\\n')\n",
    "    for y in x:\n",
    "        h.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h[len(h)-2]\n",
    "new = [h[len(h)-2]]\n",
    "x = 0\n",
    "while x < len(h)-2:\n",
    "    new.append(h[x])\n",
    "    x = x+1\n",
    "new = \"\\n\".join(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(file[:-4]+'_int.tsv', 'w')\n",
    "f.write(new)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = file[:-4]+'_int.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Abre o ficheiro .tsv no pandas\n",
    "df = pd.read_csv(file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Anota os compostos do KEGG\n",
    "def kegg(c):\n",
    "    k = requests.get('http://rest.kegg.jp/get/' + c).text\n",
    "    if 'BRITE' not in k:\n",
    "        if 'LIPIDMAPS:' in k:\n",
    "            k = k.splitlines()\n",
    "            for x in k:\n",
    "                if 'LIPIDMAPS:' in x:\n",
    "                    x = x[len('            LIPIDMAPS: '):]\n",
    "                    a = lipidmaps(x)\n",
    "                    mm = a[0]\n",
    "                    cc = a[1]\n",
    "                    ss = a[2]\n",
    "                    tt = a[3]\n",
    "                    return (mm, cc, ss, tt)\n",
    "                else:\n",
    "                    continue\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        major=[]\n",
    "        clas=[]\n",
    "        second=[]\n",
    "        third=[]\n",
    "        k = k.split('BRIT', 1)[1]\n",
    "        k = k.split('DBLINKS', 1)[0]\n",
    "        k = k.splitlines()\n",
    "        l = []\n",
    "        for x in k:\n",
    "            if x.startswith('E       '):\n",
    "                l.append('            ' + x[len('E       '):])\n",
    "            else:\n",
    "                l.append(x)\n",
    "        l = \"\\n\".join(l)\n",
    "        l = l.split('           ')[1:]\n",
    "        p = []\n",
    "        for x in l:\n",
    "            if not x.startswith('  '):\n",
    "                x = ('??'+x)\n",
    "                p.append(x)\n",
    "            else:\n",
    "                p.append(x)\n",
    "        p = \"\".join(p)\n",
    "        p = p.split('??')\n",
    "        for o in range(10):\n",
    "            for x in p:\n",
    "                if any([y in x for y in blacklist]):\n",
    "                    p.remove(x)\n",
    "        p = \"\\n\".join(p)\n",
    "        p = p.splitlines()\n",
    "        for x in p:\n",
    "            if x.startswith(' ') and not x.startswith('  '):\n",
    "                major.append(x[1:])\n",
    "            elif x.startswith('  ') and not x.startswith('   '):\n",
    "                clas.append(x[2:])\n",
    "            elif x.startswith('   ') and not x.startswith('    '):\n",
    "                second.append(x[3:])\n",
    "            elif x.startswith('    ') and not x.startswith('     '):\n",
    "                third.append(x[4:])\n",
    "        mm = \"#\".join(major)\n",
    "        cc = \"#\".join(clas)\n",
    "        ss = \"#\".join(second)\n",
    "        tt = \"#\".join(third)\n",
    "        return (mm, cc, ss, tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Anota os compostos do LipidMaps\n",
    "def lipidmaps(x):\n",
    "    f = requests.get('http://www.lipidmaps.org/rest/compound/lm_id/' + x + '/all/json')\n",
    "    s = json.loads(f.text)\n",
    "    if f.text == '[]':\n",
    "        mm = 'null'\n",
    "        cc = 'null'\n",
    "        ss = 'null'\n",
    "        tt = 'null'\n",
    "        return (mm, cc, ss, tt)\n",
    "    if s['core'] != None:\n",
    "        mm = 'Lipids [LM]'\n",
    "        cc = s['core']\n",
    "    else:\n",
    "        mm = 'Lipids [LM]'\n",
    "        cc = 'null'\n",
    "    if s['main_class'] != None:\n",
    "        ss = s['main_class']\n",
    "    else:\n",
    "        ss = 'null'\n",
    "    if s['sub_class'] != None:\n",
    "        tt = s['sub_class']\n",
    "    else:\n",
    "        tt = 'null'\n",
    "    return (mm, cc, ss, tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Diz se o composto está presente em plantas (Plantae), através da base de dados knapsack\n",
    "def knap(c):\n",
    "    m = requests.get('http://rest.kegg.jp/get/' + c).text\n",
    "    if 'KNApSAcK' in m:\n",
    "        m = m.splitlines()\n",
    "        for x in m:\n",
    "            if x.startswith('            KNApSAcK: '):\n",
    "                r = requests.post('http://kanaya.naist.jp/knapsack_jsp/information.jsp?sname=C_ID&word=' + (x[len('            KNApSAcK: '):]))\n",
    "                if 'Plantae' in r.text:\n",
    "                    return 'Plantae'\n",
    "                else:\n",
    "                    return ''\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Anota as 4 classes, dependendo se é código kegg, ou lipidmaps\n",
    "def anotar(x):\n",
    "    global count\n",
    "    splittext = x.split('#')\n",
    "    major=[]\n",
    "    clas=[]\n",
    "    second=[]\n",
    "    third=[]\n",
    "    for y in splittext:\n",
    "        if y.startswith('C'):\n",
    "            a = kegg(y)\n",
    "            if a != None :\n",
    "                major.append(a[0])\n",
    "                clas.append(a[1])\n",
    "                second.append(a[2])\n",
    "                third.append(a[3])\n",
    "            else:\n",
    "                continue\n",
    "        elif y.startswith('L'):\n",
    "            a = lipidmaps(y)\n",
    "            major.append(a[0])\n",
    "            clas.append(a[1])\n",
    "            second.append(a[2])\n",
    "            third.append(a[3])\n",
    "        else:\n",
    "            continue\n",
    "    clear_output()\n",
    "    count=count+1\n",
    "    print (str(round((1-((total-count)/total))*100)) + \"% concluído\")\n",
    "    \n",
    "    major = \"#\".join(set(major))\n",
    "    clas = \"#\".join(set(clas))\n",
    "    second = \"#\".join(set(second))\n",
    "    third = \"#\".join(set(third))\n",
    "    \n",
    "    return pd.Series([major,clas,second,third], index=['Major Class', 'Class', 'Secondary Class', 'Tertiary Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chama a função knap, para os diferentes compostos\n",
    "def knapsack(x):\n",
    "    global count\n",
    "    splittext = x.split('#')\n",
    "    knapsack=[]\n",
    "    for y in splittext:\n",
    "        if y.startswith('C'):\n",
    "            knapsack.append(knap(y))\n",
    "        else:\n",
    "            continue\n",
    "    clear_output()\n",
    "    count=count+1\n",
    "    print (str(round((1-((total-count)/total))*100)) + \"% concluído\")\n",
    "    return \"\".join(set(knapsack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cria BlackList com base nos códigos br:####### presentes no ficheiro blacklist.txt\n",
    "blacklist=[]\n",
    "with open('blacklist.txt', 'r') as f:\n",
    "    x = f.read()\n",
    "    x = x.split('\\n')\n",
    "    for y in x:\n",
    "        blacklist.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dicionário de conversão de HMDB para KEGG\n",
    "h = requests.post('http://rest.genome.jp/link/compound/hmdb').text.splitlines()\n",
    "dic = {}\n",
    "for x in h:\n",
    "    dic[x[5:14]] = x[19:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dicionários de conversão de KEGG para Lipid Maps e Lipid Maps para KEGG\n",
    "h = requests.get('http://rest.genome.jp/link/compound/lipidmaps').text\n",
    "dicl = {} # Dicionário kegg2lipidmaps\n",
    "dicl2 = {} # Dicionário lipidmaps2kegg\n",
    "h = h.replace(\"lipidmaps:\", \"\")\n",
    "h = h.replace(\"cpd:\", \"\")\n",
    "h = h.replace(\"\\tequivalent\", \"\")\n",
    "h = h.splitlines()\n",
    "for x in h:\n",
    "    dicl[x.split(\"\\t\",1)[1]] = x.split(\"\\t\",1)[0]\n",
    "    dicl2[x.split(\"\\t\",1)[0]] = x.split(\"\\t\",1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Criar coluna de convertidos HMDB to KEGG\n",
    "def hmdb2kegg(x):\n",
    "    splittext = x.split('#')\n",
    "    convert=[]\n",
    "    for y in splittext:\n",
    "        if y in dic:\n",
    "            convert.append(dic[y])\n",
    "        else:\n",
    "            convert.append(y)\n",
    "    return \"#\".join(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Criar coluna de convertidos KEGG para Lipid Maps\n",
    "def kegg2lipidmaps(x):\n",
    "    splittext = x.split('#')\n",
    "    convert=[]\n",
    "    for y in splittext:\n",
    "        if y in dicl:\n",
    "            convert.append(dicl[y])\n",
    "        else:\n",
    "            convert.append(y)\n",
    "    return \"#\".join(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Criar coluna de convertidos KEGG para Lipid Maps\n",
    "def lipidmaps2kegg(x):\n",
    "    splittext = x.split('#')\n",
    "    convert=[]\n",
    "    for y in splittext:\n",
    "        if y in dicl2:\n",
    "            convert.append(dicl2[y])\n",
    "        else:\n",
    "            convert.append(y)\n",
    "    return \"#\".join(convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retira as colunas 9 a 20, que não são necessárias\n",
    "# Exprimentei df.drop(df.columns[['nome', 'nome 2', ..., 'nome n']], axis=1, inplace=True) mas não resulta\n",
    "df.drop(df.columns[[9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Contagens para os n% concluido.\n",
    "total = len(df['raw_mass']) * 2\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Converte os códigos HMDB para KEGG, se possivél, através do dicionário \"dic\"\n",
    "df['HMDB_2_KEGG'] = df['KEGG_cid'].apply(hmdb2kegg)\n",
    "# Converte os códigos KEGG para Lipid Maps, se possível, através do dicionário \"dicl\"\n",
    "df['KEGG_2_LipidMaps'] = df['HMDB_2_KEGG'].apply(kegg2lipidmaps)\n",
    "# Converte os códigos Lipid Maps para KEGG, se possível, através do dicionário \"dicl2\"\n",
    "df['LipidMaps_2_KEGG'] = df['HMDB_2_KEGG'].apply(lipidmaps2kegg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% concluído\n"
     ]
    }
   ],
   "source": [
    "# Aplica as funções de análise de códigos KEGG e Lipid MAPS, e retorna a anotação pretendida\n",
    "df = pd.concat([df,df['KEGG_2_LipidMaps'].apply(anotar)], axis=1) # Anota os compostos nas 4 classes pretendidas.\n",
    "df['KNApSAcK'] = df['LipidMaps_2_KEGG'].apply(knapsack) # Apenas os codigos KEGG dão acesso ao knapsak, como tal a pesquiza no knapsack é feita nesta coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Guarda o novo dataframe para um ficheiro EXCEL (.xlsx) com o mesmo nome do ficheiro .tsv, acrecentado '_no-drugs' ao nome\n",
    "writer = ExcelWriter(file[:-8]+'_no-drugs.xlsx')\n",
    "df.to_excel(writer, header=True, index=False, sheet_name='No Drugs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Faz as contagens das diferentes classes de compostos\n",
    "col = ['Major Class', 'Class', 'Secondary Class', 'Tertiary Class']\n",
    "for x in col:\n",
    "    lista = df[x].tolist()\n",
    "    lista = \"#\".join(lista)\n",
    "    lista2 = []\n",
    "    for y in lista.split(\"#\"):\n",
    "        lista2.append(y)\n",
    "    new_df = pd.Series(lista2)\n",
    "    new_df = new_df.to_frame(x)\n",
    "    major = new_df.groupby(x).size()\n",
    "    major = major.to_frame('Contagem')\n",
    "    major.to_excel(writer, header=True, index=True, sheet_name=x)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluído em: 25:25s\n"
     ]
    }
   ],
   "source": [
    "# Célula de saida\n",
    "clear_output()\n",
    "elapsed_time = time.time() - start_time\n",
    "m, s = divmod(elapsed_time, 60)\n",
    "print (\"Concluído em: \" + \"%02d:%02d\" % (m, s) + 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
